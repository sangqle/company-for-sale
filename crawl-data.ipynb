{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/mydisk/.pyenv/versions/3.8.16/envs/crawl-data-for-sale/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.12.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting certifi>=2021.10.8\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Collecting urllib3[socks]<3,>=1.26\n",
      "  Using cached urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.4-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting idna\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting attrs>=20.1.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, urllib3, sniffio, pysocks, idna, h11, exceptiongroup, certifi, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-23.1.0 certifi-2023.7.22 exceptiongroup-1.1.3 h11-0.14.0 idna-3.4 outcome-1.2.0 pysocks-1.7.1 selenium-4.12.0 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.22.2 trio-websocket-0.10.4 urllib3-2.0.4 wsproto-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/mnt/mydisk/.pyenv/versions/3.8.16/envs/crawl-data-for-sale/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using legacy 'setup.py install' for bs4, since package 'wheel' is not installed.\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "  Running setup.py install for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed beautifulsoup4-4.12.2 bs4-0.0.1 soupsieve-2.5\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/mnt/mydisk/.pyenv/versions/3.8.16/envs/crawl-data-for-sale/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def append_to_csv(file_path, data, header):\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    # Open the CSV file in append mode\n",
    "    with open(file_path, mode='a', newline='', encoding='utf-8') as csv_file:\n",
    "        # Create a CSV writer\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # If the file is new, write the header\n",
    "        if not file_exists:\n",
    "            csv_writer.writerow(header)\n",
    "\n",
    "        # Split the data string into individual values\n",
    "        values = data.split(', ')\n",
    "\n",
    "        # Write the values to the CSV file\n",
    "        csv_writer.writerow(values)\n",
    "\n",
    "# Example usage:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Function to scroll to the end of the page and click the \"Tiếp\" link\n",
    "def scroll_to_end_and_click_next(driver):\n",
    "    while True:\n",
    "        # Scroll to the end of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait for a short time to load more content if necessary (adjust this as needed)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Find the \"Tiếp\" (Next) link\n",
    "        next_link = driver.find_element_by_link_text('Tiếp')\n",
    "\n",
    "        # If the \"Tiếp\" link is not displayed, break the loop (reached the last page)\n",
    "        if not next_link.is_displayed():\n",
    "            break\n",
    "\n",
    "        # Click the \"Tiếp\" link\n",
    "        next_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extractInfo(soup):\n",
    "    try:\n",
    "        nganh_listing_txt = ''\n",
    "        logo_url = ''\n",
    "        company_name = ''\n",
    "        description = ''\n",
    "        address = ''\n",
    "        email = ''\n",
    "        website = ''\n",
    "        phone_numbers = []\n",
    "        district = ''\n",
    "        is_verified = 'yes'\n",
    "\n",
    "        try:\n",
    "            logo_url = soup.find('div', class_='logo_congty').find('img')['src']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Extract company name\n",
    "        try:\n",
    "            company_name_elem = soup.find('div', class_='listings_center')\n",
    "            if company_name_elem is not None:\n",
    "                company_name_elem = company_name_elem.find('a')\n",
    "                company_name = company_name_elem.text.strip() if company_name_elem else ''\n",
    "            else:\n",
    "                company_name_elem = soup.find('div', class_='listings_center_khongxacthuc')\n",
    "                company_name_elem = company_name_elem.find('a')\n",
    "                if company_name_elem:\n",
    "                    company_name = company_name_elem.text.strip() if company_name_elem else ''\n",
    "                    is_verified = 'no'\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Find the <div> with class \"logo_congty_diachi\"\n",
    "        try:\n",
    "            logo_congty_diachi_div = soup.find('div', class_=['logo_congty_diachi', 'listing_diachi_nologo'])\n",
    "\n",
    "            # Extract nganh_listing_txt\n",
    "            nganh_listing_txt_elem = logo_congty_diachi_div.find('span', class_='nganh_listing_txt')\n",
    "            nganh_listing_txt = nganh_listing_txt_elem.text.strip() if nganh_listing_txt_elem else ''\n",
    "\n",
    "            # Extract the address\n",
    "            address_elem = logo_congty_diachi_div.find('small')\n",
    "            address = address_elem.text.strip() if address_elem else ''\n",
    "            # Extract the phone numbers\n",
    "            phone_numbers = []\n",
    "            listing_dienthoai_div = logo_congty_diachi_div.find('div', class_='listing_dienthoai')\n",
    "            if listing_dienthoai_div:\n",
    "                phone_links = listing_dienthoai_div.find_all('a', href=True)\n",
    "                for phone_link in phone_links:\n",
    "                    hef = phone_link.get('href', '').strip()\n",
    "                    if hef.startswith('tel:'):\n",
    "                        phone_numbers.append(hef.replace('tel:', ''))\n",
    "            else:\n",
    "                phone_link = logo_congty_diachi_div.find('div', class_='p-2 pt-0 ps-0 pe-4 pb-0').find('a')\n",
    "                hef = phone_link.get('href', '').strip()\n",
    "                if hef.startswith('tel:'):\n",
    "                    phone_numbers.append(hef.replace('tel:', ''))\n",
    "        \n",
    "            # Define a regular expression pattern to match \"Q. [District]\" before \"Tp. Hồ Chí Minh\"\n",
    "            pattern = r'(.+?),\\s*Tp\\. Hồ Chí Minh'\n",
    "            # Use regular expression to find the matching part in the address\n",
    "            match = re.search(pattern, address)\n",
    "            # Extract the matching part if found\n",
    "            if match:\n",
    "                extracted_text = match.group(1).strip()\n",
    "                district = extracted_text.split(', ')[-1]\n",
    "            else:\n",
    "                extracted_text = None\n",
    "        except:\n",
    "            pass\n",
    "        # Extract description\n",
    "        try:\n",
    "            description_elem = soup.find('div', class_='div_textqc').find('small', class_='text_qc')\n",
    "            description = description_elem.text.strip() if description_elem else ''\n",
    "        except:\n",
    "            pass\n",
    "        # Extract email and website\n",
    "        try:\n",
    "            email_web_div = soup.find('div', class_='email_web_section')\n",
    "            if email_web_div:\n",
    "                # Find the <a> elements within the div\n",
    "                email_web_links = email_web_div.find_all('a')\n",
    "                for link in email_web_links:\n",
    "                    href = link.get('href', '').strip()\n",
    "                    if href.startswith('mailto:'):\n",
    "                        email = href.replace('mailto:', '')\n",
    "                    elif href and not href.startswith('javascript:'):\n",
    "                        website = href\n",
    "        except:\n",
    "            pass\n",
    "        return [nganh_listing_txt, logo_url, company_name, description, address, district, email, website, is_verified, ', '.join(phone_numbers)]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'output.csv'  # Replace with your desired CSV file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'EJOT BUIDING FASTENERS REP. OFFICE', '', '173A Nguyễn Văn Trỗi, P. 11, Q. Phú Nhuận, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH CNF Hardware', '', 'Số 333, Đường Zhen Jia Dai , Haiyan, Jiaxing Tp. Hồ Chí Minh,', '', '', '', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty Cổ Phần Bulông & Cáp Thép Sơn Hà', '', '508 C/c An Lộc 2, Đường Số 3, KĐTM An Phú An Khánh, P. An Phú, Q. 2, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Đầu Tư Thương Mại Dịch Vụ Tân Vinh Lộc', '', '227/24 Nguyễn Thị Nhỏ, P. 16, Q. 11, Tp. Hồ Chí Minh, Việt Nam', '', '', '', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH MTV TM DV Mai Tech', '', 'Số 80 Calmet, P. Nguyễn Thái Bình, Q. 1, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty CP Thương Mại & Tư Vấn Kỹ Thuật H.K.T', '', '3/43A, Đường Lê Đức Thọ, P. 15, Q. Gò Vấp, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Thái Tín Đức - Công Ty TNHH Thương Mại Dịch Vụ Thái Tín Đức', '', '275 Bình Đông, P. 11, Q. 8, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Sản Xuất & Thương Mại Tân Tài Phong', '', '150 Nguyễn Chí Thanh, P. 16, Q. 11, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Cơ Sở Đức Minh', '', '79/26/2 Bến Phú Định, P. 16, Q. 8, Tp. Hồ Chí Minh, Việt Nam', '', '', '', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Tân Đức - Công Ty TNHH Tân Đức', '', '681A Tô Ngọc Vân, P. Tam Bình, Q. Thủ Đức , Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH MTV TMDV XD Khải Minh', '', '119/68 Đặng Chất, P. 2, Q. 8, Tp. Hồ Chí Minh, Việt Nam', '', '', '', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Dịch Vụ Thương Mại Cơ Khí Nguyễn Duy', '', 'Đường Liên Khu 4-5, P. Vĩnh Lộc, Q. Bình Tân, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Kỹ Thuật Thép Nam Việt', '', '106/2/1 Đường Số 6, P. Linh Xuân, Q. Thủ Đức, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH MTV XNK Kim Việt Trung', '', '232B Lưu Hữu Phước, P. 15, Q. 8 Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'yes', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH TM DV The Wings', '', '270 Tân Phước, P. 6, Q. 10, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Thương Mại Và Kim Khí Thành Phương', '', 'Quầy Số 9 Toà Nhà Thời Đại, Chợ Sắt, Đường Nguyễn Thái Học, P. Phạm Hồng Thái, Q. Hồng Bàng, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Sản Xuất Thương Mại Dịch Vụ Xây Dựng Cơ Khí Tấn Trung', '', '102 Huỳnh Mẫn Đạt, Phường 7, Quận 5, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Liên Hợp - Công Ty TNHH Sản Xuất & Thương Mại Liên Hợp', '', '236/9A Bình Long - Phường Phú Thạnh - Quận Tân Phú, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Cửa Hàng Thanh Loan', '', 'Khu Đô Thị Việt Mỹ, Thị Trấn Lai Cách, Cẩm Giàng, Hải Dương, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH ĐTTM & DV Tân Quang', '', 'A309-E2 Tòa Nhà Sunview, Đường Cây Keo, KP.1, P.Tam Phú, Q.Thủ Đức, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Doanh Nghiệp Tư Nhân Thương Mại Kim Nguyên', '', '186C Lương Nhữ Học, P. 11, Q. 5, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Hoằng Lợi', '', 'Số 29 Đường Số 3A, KDC Conic, Ấp 5, X. Phong Phú, H. Bình Chánh, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Thương Mại Dịch Vụ Hiền Thu', '', '30G/1, Đường HT 17, KP2, P. Hiệp Thành, Q. 12, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Tư Vấn Thương Mại & Đầu Tư Thuận Vũ', '', '2/47D KP.5, Phường Tân Hưng Thuận, Quận 12, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công ty TNHH Thương Mại Vân Sơn', '', 'Quốc Lộ 50, A3/ 98A, ấp 1, X. Đa Phước, H. Bình Chánh, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Tán Rút Dụ Phong Hồ Nam Trung Quốc', '', 'Số 4, Đường Số 2, Cư Xá Bình Thới, P. 8, Q. 11, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty Bù Lon ốc Vít Xuân Thành', '', 'Số 28 Lương Nhữ Học, P. 10, Q. 5, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'no', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Bulong Bình Tân Sài Gòn - Công Ty CP Công Nghiệp Bình Tân Sài Gòn - BITACO', '', 'Tầng 5 & 6, Tòa Nhà Fimexco, 231 - 233 Lê Thánh Tôn, P. Bến Thành,  Q.1, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'yes', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Bulong ốc Vít Việt Kiều Tuấn - Công Ty TNHH Thương Mại Dịch Vụ Sản Xuất Việt Kiều Tuấn', '', '282 Lý Thường Kiệt, P. 14, Q. 10, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'yes', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Cơ Khí Nam Anh - Công Ty TNHH Thương Mại Dịch Vụ Cơ Khí Nam Anh', '', '34 Đường Số 3, P. Tân Phú, Q. 7, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'yes', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty CP Đầu Tư Giải Pháp Mới', '', '596/49D Điện Biên Phủ, P. 22, Q. Bình Thạnh, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'yes', '']\n",
      "['ốc vít bulong bulong ốc vít  ở tại  tp. hồ chí minh', '', 'Công Ty Cổ Phần Cơ Khí Và Đầu Tư Ngôi Sao', '', 'VP Và Nhà máy: Lô C30, Đường 16, KCN Hiệp Phước, P. Hiệp Phước, H. Nhà Bè, Tp. Hồ Chí Minh, Việt Nam', '', '', '#', 'yes', '']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "excel_file_path = 'output.xlsx'\n",
    "\n",
    "# Function to extract page IDs and click each page to crawl data\n",
    "def crawl_multiple_pages(url, delay=20):\n",
    "    options = Options()\n",
    "    options.page_load_strategy = 'normal'\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(delay)\n",
    "\n",
    "    try:\n",
    "        # Extract the content inside the iframe\n",
    "        iframe_content = driver.page_source\n",
    "\n",
    "        # Parse the iframe content with BeautifulSoup\n",
    "        soup = BeautifulSoup(iframe_content, 'html.parser')\n",
    "\n",
    "        # Extract and process data as needed\n",
    "        div_list_company = soup.find_all('div', class_='div_list_cty')\n",
    "        div_list_company_element = div_list_company[0].find_all('div', class_='w-100 h-auto shadow rounded-3 bg-white p-2 mb-3')\n",
    "        print(len(div_list_company_element))\n",
    "        list_data = [] \n",
    "        for div_company in div_list_company_element:\n",
    "            data = extractInfo(div_company)\n",
    "            if data:\n",
    "                append_to_excel(data, 'oc-vit-bulong.xlsx')\n",
    "                print(data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage:\n",
    "crawl_multiple_pages('https://trangvangvietnam.com/cateprovinces/31960/%E1%BB%91c-v%C3%ADt-bulong-bulong-%E1%BB%91c-v%C3%ADt-%E1%BB%9F-t%E1%BA%A1i-tp.-h%E1%BB%93-ch%C3%AD-minh-(tphcm).html?page=6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "def append_to_excel(data, excel_file):\n",
    "    try:\n",
    "        # Load the existing workbook\n",
    "        workbook = openpyxl.load_workbook(excel_file)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new workbook\n",
    "        workbook = openpyxl.Workbook()\n",
    "\n",
    "    # Select the active sheet (usually the first sheet)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Find the next available row in the sheet\n",
    "    next_row = sheet.max_row + 1\n",
    "\n",
    "    # Iterate through the data and write to the next available row\n",
    "    for col, value in enumerate(data, start=1):\n",
    "        cell = sheet.cell(row=next_row, column=col)\n",
    "        cell.value = value\n",
    "\n",
    "    # Save the workbook to the Excel file, overwriting the existing file\n",
    "    workbook.save(excel_file)\n",
    "\n",
    "# # Example usage:\n",
    "# data = [\n",
    "#     'bàn ghế nội thất  ở tại  tp. hồ chí minh', '', 'Công Ty TNHH Thiết Kế Thi Công Nội Thất Tinhome', '',\n",
    "#     'Số 6, Đường Số 8, P. Bình Hưng Hòa B, Q. Bình Tân, Tp. Hồ Chí Minh, Việt Nam', 'Q. Bình Tân',\n",
    "#     'tinhomevn@gmail.com', 'http://tinhome.vn', 'no', '0908391297'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the Excel file path\n",
    "\n",
    "# Specify the Excel sheet name (optional)\n",
    "# sheet_name = 'Sheet1'\n",
    "\n",
    "# Call the function to write data to the Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9563.96s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/mnt/mydisk/.pyenv/versions/3.8.16/envs/crawl-data-for-sale/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl-data-for-sale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
